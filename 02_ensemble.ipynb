{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_ensemble.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sabyasm/manu_data_competition/blob/master/02_ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "aSQf2BcvARDc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Mlens for Ensemble and viz of model correlation"
      ]
    },
    {
      "metadata": {
        "id": "wCau82xzPNLy",
        "colab_type": "code",
        "outputId": "18ef16c9-f629-446c-cefb-62b681260f10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U mlens"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mlens\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/f7/c04bda423ac93ddb54bc4c3a21c79c9a24bc83844efc30dc4c11c289e894/mlens-0.2.3-py2.py3-none-any.whl (227kB)\n",
            "\r\u001b[K    4% |█▍                              | 10kB 16.2MB/s eta 0:00:01\r\u001b[K    8% |██▉                             | 20kB 4.5MB/s eta 0:00:01\r\u001b[K    13% |████▎                           | 30kB 6.3MB/s eta 0:00:01\r\u001b[K    17% |█████▊                          | 40kB 4.0MB/s eta 0:00:01\r\u001b[K    22% |███████▏                        | 51kB 4.9MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 61kB 5.7MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 71kB 6.4MB/s eta 0:00:01\r\u001b[K    35% |███████████▌                    | 81kB 7.2MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 92kB 7.9MB/s eta 0:00:01\r\u001b[K    44% |██████████████▍                 | 102kB 6.5MB/s eta 0:00:01\r\u001b[K    49% |███████████████▉                | 112kB 6.6MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▎              | 122kB 8.7MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▊             | 133kB 8.6MB/s eta 0:00:01\r\u001b[K    62% |████████████████████▏           | 143kB 14.9MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▋          | 153kB 15.0MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 163kB 14.9MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▌       | 174kB 15.1MB/s eta 0:00:01\r\u001b[K    80% |██████████████████████████      | 184kB 15.0MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▍    | 194kB 14.9MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▉   | 204kB 18.1MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▎ | 215kB 18.8MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▋| 225kB 18.9MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 235kB 14.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from mlens) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from mlens) (0.19.1)\n",
            "Installing collected packages: mlens\n",
            "Successfully installed mlens-0.2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4b9vqmGLmpoC",
        "colab_type": "code",
        "outputId": "141ad8f9-40c1-41ef-ac88-8305d97242db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "\n",
        "from mlens.metrics import make_scorer\n",
        "accuracy_scorer = make_scorer(accuracy_score, greater_is_better=True)\n",
        "\n",
        "\n",
        "from mlens.ensemble import SuperLearner\n",
        "from mlens.model_selection import Evaluator\n",
        "from mlens.ensemble import SequentialEnsemble\n",
        "\n",
        "# A host of Scikit-learn models\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.kernel_approximation import Nystroem\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from scipy.stats import randint\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[MLENS] backend: threading\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "YVxMX7hGMmhJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Download Feature Data stored in pickle format**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "46DAn-ZrMXyb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wezBVdtpAfYF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Change the id value from last notebook - alternatively use mine as is"
      ]
    },
    {
      "metadata": {
        "id": "4obHKh1rMujS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "download = drive.CreateFile({'id': '1xGT1h3XgWEmZTEkDPMpKIyK7odRNCqy6'})\n",
        "download.GetContentFile('final_features.pkl')\n",
        "\n",
        "#https://drive.google.com/open?id=1xGT1h3XgWEmZTEkDPMpKIyK7odRNCqy6 -- this is the url of my gdrive location. you can use this or create your own"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9gWa3ZOqM97K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Assuming pickle feats are already downloaded\n",
        "import pickle\n",
        "file = open('final_features.pkl', 'rb')\n",
        "labels = [[],[]]\n",
        "train_features = pickle.load(file)\n",
        "test_features = pickle.load(file)\n",
        "labels[0] = pickle.load(file)\n",
        "labels[1] = pickle.load(file)\n",
        "uid = pickle.load(file)\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wvx7kGjimy6R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xtrain, xtest, ytrain = train_features, test_features, np.array(labels[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DiqiJft__uR8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Ensemble of non highly correlated base models - each results 73-77% accuracy\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Note: This step takes around 1hr-1 hr 20 mins."
      ]
    },
    {
      "metadata": {
        "id": "3WF8ky7Ka-TV",
        "colab_type": "code",
        "outputId": "5bb904d4-f379-40fe-94be-93a376cb86ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5331
        }
      },
      "cell_type": "code",
      "source": [
        "# stable CV - Adam confirmed 79.07% Acc - 5th Nov submission\n",
        "\n",
        "%%time\n",
        "seed = 2017\n",
        "np.random.seed(seed)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
        "\n",
        "ensemble = SequentialEnsemble()\n",
        "\n",
        "# The initial layer is a blended layer, same as a layer in the BlendEnsemble\n",
        "ensemble.add('blend',\n",
        "             [LogisticRegression(C=1), \n",
        "              RandomForestClassifier(random_state=seed, n_jobs=-1),\n",
        "              MLPClassifier((80, 10), early_stopping=False, random_state=seed,verbose=1),\n",
        "              GradientBoostingClassifier(n_estimators=100, random_state=seed)\n",
        "             ])\n",
        "\n",
        "# The second layer is a stacked layer, same as a layer of the SuperLearner\n",
        "ensemble.add('stack', \n",
        "             [LogisticRegression(C=1), \n",
        "              RandomForestClassifier(random_state=seed, n_jobs=-1),\n",
        "              MLPClassifier((80, 10), early_stopping=False, random_state=seed,verbose=1),\n",
        "              xgb.XGBClassifier(silent=True, n_estimators=120, max_depth=7),\n",
        "             ])\n",
        "\n",
        "# The third layer is a subsembled layer, same as a layer of the Subsemble\n",
        "ensemble.add('subsemble', [SVC(), xgb.XGBClassifier(silent=True, n_estimators=120, max_depth=7),GaussianNB(),LogisticRegression(C=1)])\n",
        "\n",
        "# The meta estimator is added as in any other ensemble\n",
        "ensemble.add_meta(RandomForestClassifier(random_state=seed))\n",
        "\n",
        "# Fit ensemble\n",
        "ensemble.fit(xtrain, ytrain)\n",
        "\n",
        "# Predict\n",
        "preds = ensemble.predict(xtest)\n",
        "print(\"Fit data:\\n%r\" % ensemble.data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.57237954\n",
            "Iteration 2, loss = 0.48625287\n",
            "Iteration 3, loss = 0.46510122\n",
            "Iteration 4, loss = 0.43994066\n",
            "Iteration 5, loss = 0.41058972\n",
            "Iteration 6, loss = 0.38506532\n",
            "Iteration 7, loss = 0.36606947\n",
            "Iteration 8, loss = 0.33814708\n",
            "Iteration 9, loss = 0.31588283\n",
            "Iteration 10, loss = 0.28227581\n",
            "Iteration 11, loss = 0.26030913\n",
            "Iteration 12, loss = 0.23270564\n",
            "Iteration 13, loss = 0.20569402\n",
            "Iteration 14, loss = 0.18669746\n",
            "Iteration 15, loss = 0.15554527\n",
            "Iteration 16, loss = 0.14285135\n",
            "Iteration 17, loss = 0.12167131\n",
            "Iteration 18, loss = 0.10843283\n",
            "Iteration 19, loss = 0.08802905\n",
            "Iteration 20, loss = 0.07835036\n",
            "Iteration 21, loss = 0.07718902\n",
            "Iteration 22, loss = 0.06067011\n",
            "Iteration 23, loss = 0.05008399\n",
            "Iteration 24, loss = 0.04408593\n",
            "Iteration 25, loss = 0.03842513\n",
            "Iteration 26, loss = 0.03402232\n",
            "Iteration 27, loss = 0.03139835\n",
            "Iteration 28, loss = 0.02618692\n",
            "Iteration 29, loss = 0.02402492\n",
            "Iteration 30, loss = 0.02140145\n",
            "Iteration 31, loss = 0.01961303\n",
            "Iteration 32, loss = 0.01806661\n",
            "Iteration 33, loss = 0.01642048\n",
            "Iteration 34, loss = 0.01569366\n",
            "Iteration 35, loss = 0.01366876\n",
            "Iteration 36, loss = 0.01278195\n",
            "Iteration 37, loss = 0.01114423\n",
            "Iteration 38, loss = 0.01082571\n",
            "Iteration 39, loss = 0.01040089\n",
            "Iteration 40, loss = 0.00916684\n",
            "Iteration 41, loss = 0.00826053\n",
            "Iteration 42, loss = 0.00761106\n",
            "Iteration 43, loss = 0.00754737\n",
            "Iteration 44, loss = 0.00666776\n",
            "Iteration 45, loss = 0.00652895\n",
            "Iteration 46, loss = 0.00608658\n",
            "Iteration 47, loss = 0.00566583\n",
            "Iteration 48, loss = 0.00548684\n",
            "Iteration 49, loss = 0.00514596\n",
            "Iteration 50, loss = 0.00500009\n",
            "Iteration 51, loss = 0.00468923\n",
            "Iteration 52, loss = 0.00444237\n",
            "Iteration 53, loss = 0.00421430\n",
            "Iteration 54, loss = 0.00402411\n",
            "Iteration 55, loss = 0.00397393\n",
            "Iteration 56, loss = 0.00398146\n",
            "Iteration 57, loss = 0.00356685\n",
            "Iteration 58, loss = 0.00348296\n",
            "Iteration 59, loss = 0.00331870\n",
            "Iteration 60, loss = 0.00317513\n",
            "Iteration 61, loss = 0.00308964\n",
            "Iteration 62, loss = 0.00316051\n",
            "Iteration 63, loss = 0.00289939\n",
            "Iteration 64, loss = 0.00291332\n",
            "Iteration 65, loss = 0.00273427\n",
            "Iteration 66, loss = 0.00263012\n",
            "Iteration 67, loss = 0.00257484\n",
            "Iteration 68, loss = 0.00251672\n",
            "Iteration 69, loss = 0.00262150\n",
            "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.60222447\n",
            "Iteration 2, loss = 0.52179482\n",
            "Iteration 3, loss = 0.48057549\n",
            "Iteration 4, loss = 0.44788421\n",
            "Iteration 5, loss = 0.42430949\n",
            "Iteration 6, loss = 0.38672895\n",
            "Iteration 7, loss = 0.36273072\n",
            "Iteration 8, loss = 0.33217386\n",
            "Iteration 9, loss = 0.29689344\n",
            "Iteration 10, loss = 0.26897846\n",
            "Iteration 11, loss = 0.23880205\n",
            "Iteration 12, loss = 0.21344820\n",
            "Iteration 13, loss = 0.18385080\n",
            "Iteration 14, loss = 0.16314130\n",
            "Iteration 15, loss = 0.13707960\n",
            "Iteration 16, loss = 0.12749479\n",
            "Iteration 17, loss = 0.11171832\n",
            "Iteration 18, loss = 0.09172164\n",
            "Iteration 19, loss = 0.07738606\n",
            "Iteration 20, loss = 0.06893365\n",
            "Iteration 21, loss = 0.05965339\n",
            "Iteration 22, loss = 0.05273245\n",
            "Iteration 23, loss = 0.04683906\n",
            "Iteration 24, loss = 0.04116969\n",
            "Iteration 25, loss = 0.03677742\n",
            "Iteration 26, loss = 0.03394814\n",
            "Iteration 27, loss = 0.03026168\n",
            "Iteration 28, loss = 0.02706780\n",
            "Iteration 29, loss = 0.02403868\n",
            "Iteration 30, loss = 0.02205152\n",
            "Iteration 31, loss = 0.02026158\n",
            "Iteration 32, loss = 0.01830120\n",
            "Iteration 33, loss = 0.01843376\n",
            "Iteration 34, loss = 0.01538070\n",
            "Iteration 35, loss = 0.01426526\n",
            "Iteration 36, loss = 0.01328619\n",
            "Iteration 37, loss = 0.01256360\n",
            "Iteration 38, loss = 0.01165207\n",
            "Iteration 39, loss = 0.01060656\n",
            "Iteration 40, loss = 0.00983793\n",
            "Iteration 41, loss = 0.00947519\n",
            "Iteration 42, loss = 0.00866669\n",
            "Iteration 43, loss = 0.00813628\n",
            "Iteration 44, loss = 0.00768558\n",
            "Iteration 45, loss = 0.00723607\n",
            "Iteration 46, loss = 0.00711440\n",
            "Iteration 47, loss = 0.00674419\n",
            "Iteration 48, loss = 0.00614552\n",
            "Iteration 49, loss = 0.00592569\n",
            "Iteration 50, loss = 0.00567397\n",
            "Iteration 51, loss = 0.00547874\n",
            "Iteration 52, loss = 0.00525706\n",
            "Iteration 53, loss = 0.00497201\n",
            "Iteration 54, loss = 0.00465030\n",
            "Iteration 55, loss = 0.00446867\n",
            "Iteration 56, loss = 0.00436636\n",
            "Iteration 57, loss = 0.00419042\n",
            "Iteration 58, loss = 0.00400857\n",
            "Iteration 59, loss = 0.00383054\n",
            "Iteration 60, loss = 0.00387495\n",
            "Iteration 61, loss = 0.00369663\n",
            "Iteration 62, loss = 0.00344154\n",
            "Iteration 63, loss = 0.00324829\n",
            "Iteration 64, loss = 0.00317839\n",
            "Iteration 65, loss = 0.00304672\n",
            "Iteration 66, loss = 0.00297476\n",
            "Iteration 67, loss = 0.00289756\n",
            "Iteration 68, loss = 0.00282886\n",
            "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.85400383\n",
            "Iteration 1, loss = 0.81902735\n",
            "Iteration 2, loss = 0.80430205\n",
            "Iteration 3, loss = 0.75216757\n",
            "Iteration 2, loss = 0.72459424\n",
            "Iteration 4, loss = 0.70633332\n",
            "Iteration 5, loss = 0.65676744\n",
            "Iteration 3, loss = 0.63450329\n",
            "Iteration 6, loss = 0.60927005\n",
            "Iteration 7, loss = 0.57022526\n",
            "Iteration 4, loss = 0.56704972\n",
            "Iteration 8, loss = 0.54075366\n",
            "Iteration 9, loss = 0.52084953\n",
            "Iteration 5, loss = 0.53503906\n",
            "Iteration 10, loss = 0.50971013\n",
            "Iteration 11, loss = 0.50450346\n",
            "Iteration 6, loss = 0.52536062\n",
            "Iteration 12, loss = 0.50072048\n",
            "Iteration 13, loss = 0.49814178\n",
            "Iteration 14, loss = 0.49561060\n",
            "Iteration 7, loss = 0.52015449\n",
            "Iteration 15, loss = 0.49318498\n",
            "Iteration 16, loss = 0.49095885\n",
            "Iteration 8, loss = 0.51566673\n",
            "Iteration 17, loss = 0.48931493\n",
            "Iteration 18, loss = 0.48788307\n",
            "Iteration 9, loss = 0.51223272\n",
            "Iteration 19, loss = 0.48635289\n",
            "Iteration 20, loss = 0.48497232\n",
            "Iteration 10, loss = 0.50943809\n",
            "Iteration 21, loss = 0.48366385\n",
            "Iteration 22, loss = 0.48242560\n",
            "Iteration 11, loss = 0.50708764\n",
            "Iteration 23, loss = 0.48122456\n",
            "Iteration 24, loss = 0.48008270\n",
            "Iteration 12, loss = 0.50512882\n",
            "Iteration 25, loss = 0.47929967\n",
            "Iteration 26, loss = 0.47874945\n",
            "Iteration 13, loss = 0.50403908\n",
            "Iteration 27, loss = 0.47824935\n",
            "Iteration 14, loss = 0.50287708\n",
            "Iteration 28, loss = 0.47766517\n",
            "Iteration 29, loss = 0.47715102\n",
            "Iteration 30, loss = 0.47670174\n",
            "Iteration 15, loss = 0.50194802\n",
            "Iteration 31, loss = 0.47639788\n",
            "Iteration 32, loss = 0.47602928\n",
            "Iteration 16, loss = 0.50112196\n",
            "Iteration 33, loss = 0.47548421\n",
            "Iteration 34, loss = 0.47514565\n",
            "Iteration 17, loss = 0.50061649\n",
            "Iteration 35, loss = 0.47472841\n",
            "Iteration 36, loss = 0.47432058\n",
            "Iteration 18, loss = 0.49937689\n",
            "Iteration 37, loss = 0.47384515\n",
            "Iteration 38, loss = 0.47355346\n",
            "Iteration 19, loss = 0.49864505\n",
            "Iteration 39, loss = 0.47311060\n",
            "Iteration 40, loss = 0.47280319\n",
            "Iteration 20, loss = 0.49801950\n",
            "Iteration 41, loss = 0.47244701\n",
            "Iteration 42, loss = 0.47192059\n",
            "Iteration 21, loss = 0.49722445\n",
            "Iteration 43, loss = 0.47151551\n",
            "Iteration 44, loss = 0.47117314\n",
            "Iteration 22, loss = 0.49704145\n",
            "Iteration 45, loss = 0.47086162\n",
            "Iteration 46, loss = 0.47046221\n",
            "Iteration 23, loss = 0.49662550\n",
            "Iteration 47, loss = 0.47018158\n",
            "Iteration 48, loss = 0.46987240\n",
            "Iteration 24, loss = 0.49591125\n",
            "Iteration 49, loss = 0.46949672\n",
            "Iteration 50, loss = 0.46918106\n",
            "Iteration 25, loss = 0.49576758\n",
            "Iteration 51, loss = 0.46925580\n",
            "Iteration 52, loss = 0.46896358\n",
            "Iteration 26, loss = 0.49557459\n",
            "Iteration 53, loss = 0.46853235\n",
            "Iteration 27, loss = 0.49580993\n",
            "Iteration 54, loss = 0.46825427\n",
            "Iteration 55, loss = 0.46793475\n",
            "Iteration 56, loss = 0.46766618\n",
            "Iteration 28, loss = 0.49498531\n",
            "Iteration 57, loss = 0.46750322\n",
            "Iteration 58, loss = 0.46736066\n",
            "Iteration 29, loss = 0.49500592\n",
            "Iteration 59, loss = 0.46702701\n",
            "Iteration 60, loss = 0.46705092\n",
            "Iteration 30, loss = 0.49491872\n",
            "Iteration 61, loss = 0.46707205\n",
            "Iteration 62, loss = 0.46668404\n",
            "Iteration 31, loss = 0.49482679\n",
            "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
            "Iteration 63, loss = 0.46668492\n",
            "Iteration 1, loss = 0.83197730\n",
            "Iteration 64, loss = 0.46658496\n",
            "Iteration 2, loss = 0.78997182\n",
            "Iteration 65, loss = 0.46619337\n",
            "Iteration 3, loss = 0.74557239\n",
            "Iteration 66, loss = 0.46607983\n",
            "Iteration 4, loss = 0.70208964\n",
            "Iteration 67, loss = 0.46602499\n",
            "Iteration 5, loss = 0.65975892\n",
            "Iteration 68, loss = 0.46637843\n",
            "Iteration 6, loss = 0.61848960\n",
            "Iteration 69, loss = 0.46590763\n",
            "Iteration 7, loss = 0.58717061\n",
            "Iteration 70, loss = 0.46595383\n",
            "Iteration 8, loss = 0.56738887\n",
            "Iteration 71, loss = 0.46567103\n",
            "Iteration 9, loss = 0.55445532Iteration 72, loss = 0.46548930\n",
            "\n",
            "Iteration 73, loss = 0.46553713Iteration 10, loss = 0.54895223\n",
            "\n",
            "Iteration 74, loss = 0.46572994Iteration 11, loss = 0.54572688\n",
            "\n",
            "Iteration 12, loss = 0.54316836\n",
            "Iteration 75, loss = 0.46536123\n",
            "Iteration 13, loss = 0.54053613\n",
            "Iteration 76, loss = 0.46531430\n",
            "Iteration 14, loss = 0.53786174\n",
            "Iteration 77, loss = 0.46539241\n",
            "Iteration 78, loss = 0.46523825Iteration 15, loss = 0.53582084\n",
            "\n",
            "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
            "Iteration 16, loss = 0.53412038\n",
            "Iteration 17, loss = 0.53243983\n",
            "Iteration 18, loss = 0.53100688\n",
            "Iteration 19, loss = 0.52944061\n",
            "Iteration 20, loss = 0.52817144\n",
            "Iteration 21, loss = 0.52702738\n",
            "Iteration 22, loss = 0.52579404\n",
            "Iteration 23, loss = 0.52467761\n",
            "Iteration 24, loss = 0.52390668\n",
            "Iteration 25, loss = 0.52328885\n",
            "Iteration 26, loss = 0.52284258\n",
            "Iteration 27, loss = 0.52240093\n",
            "Iteration 28, loss = 0.52193051\n",
            "Iteration 29, loss = 0.52148192\n",
            "Iteration 30, loss = 0.52106657\n",
            "Iteration 31, loss = 0.52070086\n",
            "Iteration 32, loss = 0.52027304\n",
            "Iteration 33, loss = 0.52018064\n",
            "Iteration 34, loss = 0.51978356\n",
            "Iteration 35, loss = 0.51960467\n",
            "Iteration 36, loss = 0.51934836\n",
            "Iteration 37, loss = 0.51908896\n",
            "Iteration 38, loss = 0.51902126\n",
            "Iteration 39, loss = 0.51866867\n",
            "Iteration 40, loss = 0.51873053\n",
            "Iteration 41, loss = 0.51831527\n",
            "Iteration 42, loss = 0.51829397\n",
            "Iteration 43, loss = 0.51834007\n",
            "Iteration 44, loss = 0.51802322\n",
            "Iteration 45, loss = 0.51792870\n",
            "Iteration 46, loss = 0.51806953\n",
            "Iteration 47, loss = 0.51768619\n",
            "Iteration 48, loss = 0.51771350\n",
            "Iteration 49, loss = 0.51753637\n",
            "Iteration 50, loss = 0.51762256\n",
            "Iteration 51, loss = 0.51774048\n",
            "Iteration 52, loss = 0.51728105\n",
            "Iteration 53, loss = 0.51730834\n",
            "Iteration 54, loss = 0.51741515\n",
            "Iteration 55, loss = 0.51727409\n",
            "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
            "Fit data:\n",
            "                                             ft-m  ft-s  pt-m  pt-s\n",
            "layer-1  gradientboostingclassifier  0    1010.90  0.00  0.19  0.00\n",
            "layer-1  logisticregression          0      19.18  0.00  0.10  0.00\n",
            "layer-1  mlpclassifier               0     179.26  0.00  0.64  0.00\n",
            "layer-1  randomforestclassifier      0       3.35  0.00  0.23  0.00\n",
            "layer-2  logisticregression          0       0.00  0.00  0.00  0.00\n",
            "layer-2  mlpclassifier               0       0.93  0.36  0.01  0.00\n",
            "layer-2  randomforestclassifier      0       0.11  0.00  0.11  0.00\n",
            "layer-2  xgbclassifier               0       0.06  0.00  0.00  0.00\n",
            "layer-3  gaussiannb                  0       0.01  0.00  0.00  0.00\n",
            "layer-3  gaussiannb                  1       0.01  0.00  0.00  0.00\n",
            "layer-3  logisticregression          0       0.00  0.00  0.00  0.00\n",
            "layer-3  logisticregression          1       0.00  0.00  0.00  0.00\n",
            "layer-3  svc                         0       0.01  0.00  0.01  0.00\n",
            "layer-3  svc                         1       0.01  0.00  0.01  0.00\n",
            "layer-3  xgbclassifier               0       0.03  0.00  0.00  0.00\n",
            "layer-3  xgbclassifier               1       0.03  0.00  0.00  0.00\n",
            "\n",
            "CPU times: user 57min 38s, sys: 2min 51s, total: 1h 30s\n",
            "Wall time: 34min 4s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7q0nM_66_lEh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Generate Prediction**"
      ]
    },
    {
      "metadata": {
        "id": "2Zv_f-BCzMb8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_name=\"sub_002_ensemble\"\n",
        "ts = pd.DataFrame(\n",
        "{'Unique ID': uid,\n",
        " 'label': preds\n",
        "})\n",
        "ts.to_csv(model_name+\".csv\",index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pVQadZx4jAcN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"sub_002_ensemble.csv\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h5nI3dd8_Xl3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Optional - Save prediction to google drive (in case runtime dies)"
      ]
    },
    {
      "metadata": {
        "id": "WprWIPgf_RfC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "upload = drive.CreateFile({'title': 'sub_002_ensemble.csv'})\n",
        "upload.SetContentFile('sub_002_ensemble.csv')\n",
        "upload.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}